{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91a6e3f6-249f-4944-9b65-eb1e2edbd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing FFT-based pCN for Allen-Cahn SPDE\n",
      "\n",
      "Small test (N=32):\n",
      "Setting up FFT-based pCN for Allen-Cahn SPDE with N=32 (dim=32)\n",
      "Discretization step size h=0.031250\n",
      "Creating FFT-based covariance operator...\n",
      "  FFT covariance operator with quadratic regularization\n",
      "  Taylor expansion: V(u) = 1 - 2u² + u⁴\n",
      "  Quadratic regularization parameter α = 0.01\n",
      "  Min eigenvalue: 1.00e-02\n",
      "  Max eigenvalue: 1.01e+04\n",
      "  Condition number: 1.01e+06\n",
      "  Constant mode eigenvalue: 1.00e-02\n",
      "Generating initial state near Allen-Cahn equilibrium...\n",
      "Running FFT-based pCN sampler...\n",
      "Warmup acceptance rate: 0.522\n",
      "Sampling acceptance rate: 0.522\n",
      "FFT pCN Results:\n",
      "  Acceptance rate: 0.52\n",
      "  Path integral mean: 0.0010\n",
      "  Path integral std: 0.8775\n",
      "  Well mixing rate: 0.4554\n",
      "  Integrated autocorrelation time: 3.67\n",
      "  Time: 32.66 seconds\n",
      "Acceptance Rate: 0.522\n",
      "Path Integral Std: 0.8775\n",
      "Well Mixing: 0.455\n",
      "ESS/sec: 4165.72\n",
      "\n",
      "Medium test (N=128):\n",
      "Setting up FFT-based pCN for Allen-Cahn SPDE with N=128 (dim=128)\n",
      "Discretization step size h=0.007812\n",
      "Creating FFT-based covariance operator...\n",
      "  FFT covariance operator with quadratic regularization\n",
      "  Taylor expansion: V(u) = 1 - 2u² + u⁴\n",
      "  Quadratic regularization parameter α = 0.01\n",
      "  Min eigenvalue: 1.00e-02\n",
      "  Max eigenvalue: 1.62e+05\n",
      "  Condition number: 1.62e+07\n",
      "  Constant mode eigenvalue: 1.00e-02\n",
      "Generating initial state near Allen-Cahn equilibrium...\n",
      "Running FFT-based pCN sampler...\n",
      "Warmup acceptance rate: 0.740\n",
      "Sampling acceptance rate: 0.740\n",
      "FFT pCN Results:\n",
      "  Acceptance rate: 0.74\n",
      "  Path integral mean: -0.0001\n",
      "  Path integral std: 0.7849\n",
      "  Well mixing rate: 0.4401\n",
      "  Integrated autocorrelation time: 3.79\n",
      "  Time: 93.00 seconds\n",
      "Acceptance Rate: 0.740\n",
      "Path Integral Std: 0.7849\n",
      "Well Mixing: 0.440\n",
      "ESS/sec: 2833.73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "\n",
    "def autocorrelation_fft(x, max_lag=None):\n",
    "    \"\"\"\n",
    "    Efficiently compute autocorrelation function using FFT.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array\n",
    "        1D array of samples\n",
    "    max_lag : int, optional\n",
    "        Maximum lag to compute (default: len(x)//3)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    acf : array\n",
    "        Autocorrelation function values\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    if max_lag is None:\n",
    "        max_lag = min(n // 3, 20000)  # Cap at 20000 to prevent slow computation\n",
    "    \n",
    "    # Remove mean and normalize\n",
    "    x_norm = x - np.mean(x)\n",
    "    var = np.var(x_norm)\n",
    "    x_norm = x_norm / np.sqrt(var)\n",
    "    \n",
    "    # Compute autocorrelation using FFT\n",
    "    # Pad the signal with zeros to avoid circular correlation\n",
    "    fft = np.fft.fft(x_norm, n=2*n)\n",
    "    acf = np.fft.ifft(fft * np.conjugate(fft))[:n]\n",
    "    acf = acf.real / n  # Normalize\n",
    "    \n",
    "    return acf[:max_lag]\n",
    "\n",
    "def integrated_autocorr_time(x, M=5, c=10):\n",
    "    \"\"\"\n",
    "    Estimate the integrated autocorrelation time using a self-consistent window.\n",
    "    Based on the algorithm described by Goodman and Weare.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array\n",
    "        1D array of samples\n",
    "    M : int, default=5\n",
    "        Window size multiplier (typically 5-10)\n",
    "    c : int, default=10\n",
    "        Maximum lag cutoff for window determination\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tau : float\n",
    "        Integrated autocorrelation time\n",
    "    acf : array\n",
    "        Autocorrelation function values\n",
    "    ess : float\n",
    "        Effective sample size\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    orig_x = x.copy()\n",
    "    \n",
    "    # Initial pairwise reduction if needed\n",
    "    k = 0\n",
    "    max_iterations = 10  # Prevent infinite loop\n",
    "    \n",
    "    while k < max_iterations:\n",
    "        # Calculate autocorrelation function\n",
    "        acf = autocorrelation_fft(x)\n",
    "        \n",
    "        # Calculate integrated autocorrelation time with self-consistent window\n",
    "        tau = 1.0  # Initialize with the first term\n",
    "        \n",
    "        # Find the window size where window <= M * tau\n",
    "        for window in range(1, len(acf)):\n",
    "            # Update tau with this window\n",
    "            tau_window = 1.0 + 2.0 * sum(acf[1:window+1])\n",
    "            \n",
    "            # Check window consistency: window <= M*tau\n",
    "            if window <= M * tau_window:\n",
    "                tau = tau_window\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # If we have a robust estimate, we're done\n",
    "        if n >= c * tau:\n",
    "            # Scale tau back to the original time scale: tau_0 = 2^k * tau_k\n",
    "            tau = tau * (2**k)\n",
    "            break\n",
    "            \n",
    "        # If we don't have a robust estimate, perform pairwise reduction\n",
    "        k += 1\n",
    "        n_half = len(x) // 2\n",
    "        x_new = np.zeros(n_half)\n",
    "        for i in range(n_half):\n",
    "            if 2*i + 1 < len(x):\n",
    "                x_new[i] = 0.5 * (x[2*i] + x[2*i+1])\n",
    "            else:\n",
    "                x_new[i] = x[2*i]\n",
    "        x = x_new\n",
    "        n = len(x)\n",
    "    \n",
    "    # If we exited without a robust estimate, compute one final estimate\n",
    "    if k >= max_iterations or n < c * tau:\n",
    "        acf = autocorrelation_fft(orig_x)\n",
    "        tau_reduced = 1.0 + 2.0 * sum(acf[1:min(len(acf), int(M)+1)])\n",
    "        # Scale tau back to the original time scale\n",
    "        tau = tau_reduced * (2**k)\n",
    "    \n",
    "    # Calculate effective sample size using original series length\n",
    "    ess = len(orig_x) / tau\n",
    "    \n",
    "    return tau, acf, ess\n",
    "\n",
    "\n",
    "class FFTCovarianceOperator:\n",
    "    \"\"\"\n",
    "    FFT-based covariance operator for periodic boundary conditions.\n",
    "    \n",
    "    We use Taylor expansion of V(u) = (1-u²)² around u=0:\n",
    "    V(u) = 1 - 2u² + u⁴\n",
    "    \n",
    "    The issue: To eliminate the quadratic term completely, we'd need α = -4,\n",
    "    but this gives negative eigenvalues (unstable).\n",
    "    \n",
    "    Instead, we use a small positive α for stability, and handle the \n",
    "    remaining quadratic term in the acceptance ratio.\n",
    "    \n",
    "    Prior: exp(-∫[½|∇u|² + ½αu²]dx) with small α > 0\n",
    "    Target: exp(-∫[½|∇u|² + 1 - 2u² + u⁴]dx)\n",
    "    \n",
    "    Acceptance ratio involves: (1 - 2u² + u⁴) - ½αu² = 1 + (-2 - ½α)u² + u⁴\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, N, h, alpha=0.01):\n",
    "        \"\"\"\n",
    "        Initialize FFT-based covariance operator with small regularization.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        N : int\n",
    "            Number of grid points\n",
    "        h : float\n",
    "            Grid spacing\n",
    "        alpha : float\n",
    "            Small regularization parameter for stability (default: 0.1)\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.h = h\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Compute eigenvalues of periodic Laplacian: -Δ + α\n",
    "        k = np.arange(N)\n",
    "        # For k > N/2, use k - N to get negative frequencies  \n",
    "        k = np.where(k > N//2, k - N, k)\n",
    "        \n",
    "        # Eigenvalues of periodic Laplacian: λₖ = (2πk)²\n",
    "        # With discretization: λₖ = (2πk/L)² where L = 1, so λₖ = (2πk)²\n",
    "        # BUT for finite differences: λₖ = 4sin²(πk/N)/h²\n",
    "        # Let's use the exact continuous eigenvalues for simplicity\n",
    "        laplacian_eigenvals = (2 * np.pi * k)**2\n",
    "        \n",
    "        # Add mass term: eigenvalues of (-Δ + α)\n",
    "        self.eigenvalues = laplacian_eigenvals + alpha\n",
    "        \n",
    "        # All eigenvalues are now > 0, so covariance is well-defined\n",
    "        self.cov_eigenvalues = 1.0 / self.eigenvalues\n",
    "        self.cov_sqrt_eigenvalues = np.sqrt(self.cov_eigenvalues)\n",
    "        \n",
    "        print(f\"  FFT covariance operator with quadratic regularization\")\n",
    "        print(f\"  Taylor expansion: V(u) = 1 - 2u² + u⁴\")\n",
    "        print(f\"  Quadratic regularization parameter α = {alpha}\")\n",
    "        print(f\"  Min eigenvalue: {np.min(self.eigenvalues):.2e}\")\n",
    "        print(f\"  Max eigenvalue: {np.max(self.eigenvalues):.2e}\")\n",
    "        print(f\"  Condition number: {np.max(self.eigenvalues)/np.min(self.eigenvalues):.2e}\")\n",
    "        print(f\"  Constant mode eigenvalue: {self.eigenvalues[0]:.2e}\")\n",
    "    \n",
    "    def apply_covariance(self, x):\n",
    "        \"\"\"Apply covariance operator C₀ = (-Δ + α)⁻¹ to vector x using FFT.\"\"\"\n",
    "        if x.ndim == 1:\n",
    "            # Transform to Fourier space\n",
    "            x_hat = np.fft.fft(x)\n",
    "            # Multiply by covariance eigenvalues\n",
    "            result_hat = self.cov_eigenvalues * x_hat\n",
    "            # Transform back to physical space\n",
    "            return np.real(np.fft.ifft(result_hat))\n",
    "        else:\n",
    "            # Handle multiple vectors\n",
    "            return np.array([self.apply_covariance(xi) for xi in x])\n",
    "    \n",
    "    def apply_sqrt_covariance(self, x):\n",
    "        \"\"\"Apply square root covariance operator C₀^{1/2} to vector x using FFT.\"\"\"\n",
    "        if x.ndim == 1:\n",
    "            # Transform to Fourier space\n",
    "            x_hat = np.fft.fft(x)\n",
    "            # Multiply by sqrt covariance eigenvalues\n",
    "            result_hat = self.cov_sqrt_eigenvalues * x_hat\n",
    "            # Transform back to physical space\n",
    "            return np.real(np.fft.ifft(result_hat))\n",
    "        else:\n",
    "            # Handle multiple vectors\n",
    "            return np.array([self.apply_sqrt_covariance(xi) for xi in x])\n",
    "    \n",
    "    def sample_prior(self, n_samples=1):\n",
    "        \"\"\"Generate samples from the modified Gaussian prior N(0, C₀) where C₀ = (-Δ + α)⁻¹.\"\"\"\n",
    "        if n_samples == 1:\n",
    "            # Generate white noise\n",
    "            xi = np.random.randn(self.N)\n",
    "            # Apply sqrt covariance\n",
    "            return self.apply_sqrt_covariance(xi)\n",
    "        else:\n",
    "            # Generate multiple samples\n",
    "            samples = np.zeros((n_samples, self.N))\n",
    "            for i in range(n_samples):\n",
    "                xi = np.random.randn(self.N)\n",
    "                samples[i] = self.apply_sqrt_covariance(xi)\n",
    "            return samples\n",
    "\n",
    "\n",
    "def pcn_sampler_fft(log_density, initial, n_samples, n_warmup=1000, beta=0.5, \n",
    "                   n_thin=1, cov_op=None, h=None):\n",
    "    \"\"\"\n",
    "    Preconditioned Crank-Nicolson (pCN) sampler with FFT-based covariance.\n",
    "    \n",
    "    The pCN algorithm is designed for sampling from measures on function spaces.\n",
    "    Proposal: u' = √(1-β²) * u + β * C₀^(1/2) * ξ where ξ ~ N(0, I)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    log_density : callable\n",
    "        Function that computes the log density\n",
    "    initial : np.ndarray\n",
    "        Initial state\n",
    "    n_samples : int\n",
    "        Number of samples to collect (after warmup)\n",
    "    n_warmup : int\n",
    "        Number of warmup iterations\n",
    "    beta : float\n",
    "        pCN parameter (step size), fixed\n",
    "    cov_op : FFTCovarianceOperator\n",
    "        FFT-based covariance operator\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    samples : np.ndarray\n",
    "        Collected samples (after warmup)\n",
    "    acceptance_rate : float\n",
    "        Final acceptance rate\n",
    "    \"\"\"\n",
    "    \n",
    "    dim = len(initial)\n",
    "    \n",
    "    if cov_op is None:\n",
    "        raise ValueError(\"FFT covariance operator must be provided\")\n",
    "    \n",
    "    # Calculate total iterations\n",
    "    total_sampling_iterations = n_samples * n_thin\n",
    "    total_iterations = n_warmup + total_sampling_iterations\n",
    "    \n",
    "    # Storage\n",
    "    samples = np.zeros((n_samples, dim))\n",
    "    accepts_warmup = 0\n",
    "    accepts_sampling = 0\n",
    "    \n",
    "    # Current state\n",
    "    current_u = initial.copy()\n",
    "    \n",
    "    # Sample index\n",
    "    sample_idx = 0\n",
    "    \n",
    "    for i in range(total_iterations):\n",
    "        is_warmup = i < n_warmup\n",
    "        \n",
    "        # Store sample (only during sampling phase)\n",
    "        if not is_warmup and (i - n_warmup) % n_thin == 0 and sample_idx < n_samples:\n",
    "            samples[sample_idx] = current_u\n",
    "            sample_idx += 1\n",
    "        \n",
    "        # Generate proposal using pCN with FFT-based prior covariance\n",
    "        xi = np.random.randn(dim)\n",
    "        noise = cov_op.apply_sqrt_covariance(xi)\n",
    "        proposal_u = np.sqrt(1 - beta**2) * current_u + beta * noise\n",
    "        \n",
    "        # pCN acceptance probability with corrected Taylor expansion\n",
    "        # \n",
    "        # Target: exp(-∫[½|∇u|² + 1 - 2u² + u⁴]dx)\n",
    "        # Prior:  exp(-∫[½|∇u|² + ½αu²]dx)\n",
    "        #\n",
    "        # Radon-Nikodym: exp(-∫[1 - 2u² + u⁴ - ½αu²]dx) \n",
    "        #               = exp(-∫[1 + (-2 - ½α)u² + u⁴]dx)\n",
    "        # \n",
    "        # pCN acceptance: min(1, exp(-∫[(1 + (-2-½α)u'² + u'⁴) - (1 + (-2-½α)u² + u⁴)]dx))\n",
    "        #                = min(1, exp(-∫[u'⁴ - u⁴ + (-2-½α)(u'² - u²)]dx))\n",
    "        \n",
    "        # Compute quartic terms\n",
    "        quartic_current = current_u**4\n",
    "        quartic_proposal = proposal_u**4\n",
    "        quartic_diff = h * np.sum(quartic_proposal - quartic_current)\n",
    "        \n",
    "        # Compute quadratic terms with correct coefficient\n",
    "        quadratic_current = current_u**2\n",
    "        quadratic_proposal = proposal_u**2\n",
    "        quadratic_coeff = -2 - 0.5 * cov_op.alpha\n",
    "        quadratic_diff = quadratic_coeff * h * np.sum(quadratic_proposal - quadratic_current)\n",
    "        \n",
    "        # pCN acceptance probability\n",
    "        log_alpha = -(quartic_diff + quadratic_diff)\n",
    "        accept_prob = min(1.0, np.exp(log_alpha))\n",
    "        \n",
    "        # Accept/reject\n",
    "        if np.random.rand() < accept_prob:\n",
    "            current_u = proposal_u\n",
    "            accept = True\n",
    "        else:\n",
    "            accept = False\n",
    "        \n",
    "        # Track acceptances\n",
    "        if is_warmup:\n",
    "            accepts_warmup += accept\n",
    "        else:\n",
    "            accepts_sampling += accept\n",
    "    \n",
    "    # Compute acceptance rates\n",
    "    warmup_accept_rate = accepts_warmup / n_warmup if n_warmup > 0 else 0\n",
    "    sampling_accept_rate = accepts_sampling / total_sampling_iterations\n",
    "    \n",
    "    print(f\"Warmup acceptance rate: {warmup_accept_rate:.3f}\")\n",
    "    print(f\"Sampling acceptance rate: {sampling_accept_rate:.3f}\")\n",
    "    \n",
    "    return samples, sampling_accept_rate\n",
    "\n",
    "\n",
    "def benchmark_pcn_allen_cahn_fft(N=100, n_samples=10000, burn_in=1000, n_thin=1, save_dir=None):\n",
    "    \"\"\"\n",
    "    Benchmark pCN sampler on the Allen-Cahn SPDE with FFT-based periodic covariance.\n",
    "    \"\"\"\n",
    "    # Define discretization parameters  \n",
    "    h = 1.0 / N\n",
    "    dim = N  # For periodic BC, we have N points (not N+1)\n",
    "    \n",
    "    print(f\"Setting up FFT-based pCN for Allen-Cahn SPDE with N={N} (dim={dim})\")\n",
    "    print(f\"Discretization step size h={h:.6f}\")\n",
    "    \n",
    "    # Create FFT-based covariance operator (no regularization)\n",
    "    print(\"Creating FFT-based covariance operator...\")\n",
    "    cov_op = FFTCovarianceOperator(N, h)\n",
    "    \n",
    "    # Define the log density function for periodic case\n",
    "    def log_density(u):\n",
    "        \"\"\"\n",
    "        Log density for Allen-Cahn SPDE: -∫[½|∇u|² + V(u)] dx\n",
    "        where V(u) = (1-u²)² is the double-well potential.\n",
    "        \n",
    "        Note: This is the FULL energy (gradient + potential), not just the potential part.\n",
    "        For pCN, we need the full target density, not the relative density.\n",
    "        \"\"\"\n",
    "        if u.ndim == 1:\n",
    "            u = u.reshape(1, -1)\n",
    "            \n",
    "        # Gradient term: ½∫|∇u|² dx using periodic finite differences\n",
    "        # ∇u ≈ (u[j+1] - u[j])/h for periodic BC\n",
    "        u_shifted = np.roll(u, -1, axis=1)  # u[j+1] with periodic wraparound\n",
    "        gradients = (u_shifted - u) / h  # Finite difference approximation\n",
    "        gradient_term = 0.5 * h * np.sum(gradients**2, axis=1)  # ½∫|∇u|² dx\n",
    "        \n",
    "        # Potential term: ∫V(u) dx where V(u) = (1-u²)²\n",
    "        v_values = (1 - u**2)**2\n",
    "        potential_term = h * np.sum(v_values, axis=1)\n",
    "        \n",
    "        # Total energy = gradient + potential\n",
    "        total_energy = gradient_term + potential_term\n",
    "        \n",
    "        # Log density = -energy (we want to sample from exp(-energy))\n",
    "        log_dens = -total_energy\n",
    "            \n",
    "        return log_dens\n",
    "    \n",
    "    # Function to compute path integral for periodic case\n",
    "    def compute_path_integral(path):\n",
    "        \"\"\"Calculate path integral ∫u(x)dx for periodic domain\"\"\"\n",
    "        if path.ndim > 1:\n",
    "            return np.array([compute_path_integral(p) for p in path])\n",
    "        \n",
    "        # For periodic domain [0,1) with N points, integral is h * sum(u)\n",
    "        return h * np.sum(path)\n",
    "    \n",
    "    # Initial state - start from a state closer to Allen-Cahn equilibrium\n",
    "    print(\"Generating initial state near Allen-Cahn equilibrium...\")\n",
    "    # Start with u ≈ +1 with small perturbations instead of Gaussian prior\n",
    "    initial = np.ones(dim) + 0.1 * np.random.randn(dim)\n",
    "    \n",
    "    # Run pCN sampler\n",
    "    print(\"Running FFT-based pCN sampler...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        samples, acceptance_rate = pcn_sampler_fft(\n",
    "            log_density=log_density, \n",
    "            initial=initial, \n",
    "            n_samples=n_samples, \n",
    "            n_warmup=burn_in,\n",
    "            beta=0.9,  # Even larger beta for exploration between wells\n",
    "            n_thin=n_thin,\n",
    "            cov_op=cov_op,\n",
    "            h=h  # Pass discretization step size\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        # Compute diagnostics\n",
    "        sample_mean = np.mean(samples, axis=0)\n",
    "        \n",
    "        # Calculate path integrals\n",
    "        path_integrals = compute_path_integral(samples)\n",
    "        mean_path_integral = np.mean(path_integrals)\n",
    "        path_integral_std = np.std(path_integrals)\n",
    "        \n",
    "        # Compute energies\n",
    "        log_densities = log_density(samples)\n",
    "        energies = -log_densities\n",
    "        mean_energy = np.mean(energies)\n",
    "        energy_std = np.std(energies)\n",
    "        \n",
    "        # Check well mixing with better thresholds for Allen-Cahn\n",
    "        positive_well = np.mean(path_integrals > 0.2)  # Threshold for +1 well\n",
    "        negative_well = np.mean(path_integrals < -0.2)  # Threshold for -1 well\n",
    "        well_mixing = min(positive_well, negative_well)\n",
    "        \n",
    "        # Autocorrelation analysis\n",
    "        acf = autocorrelation_fft(path_integrals)\n",
    "        \n",
    "        try:\n",
    "            tau, _, ess = integrated_autocorr_time(path_integrals)\n",
    "        except:\n",
    "            tau, ess = np.nan, np.nan\n",
    "            print(\"Warning: Could not compute integrated autocorrelation time\")\n",
    "        \n",
    "        # Positive fraction\n",
    "        positive_fraction = np.mean(samples > 0)\n",
    "        \n",
    "        print(f\"FFT pCN Results:\")\n",
    "        print(f\"  Acceptance rate: {acceptance_rate:.2f}\")\n",
    "        print(f\"  Path integral mean: {mean_path_integral:.4f}\")\n",
    "        print(f\"  Path integral std: {path_integral_std:.4f}\")\n",
    "        print(f\"  Well mixing rate: {well_mixing:.4f}\")\n",
    "        print(f\"  Integrated autocorrelation time: {tau:.2f}\" if np.isfinite(tau) else \"  Integrated autocorrelation time: NaN\")\n",
    "        print(f\"  Time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            \"samples\": samples,\n",
    "            \"acceptance_rate\": acceptance_rate,\n",
    "            \"path_integrals\": path_integrals,\n",
    "            \"path_integral_mean\": mean_path_integral,\n",
    "            \"path_integral_std\": path_integral_std,\n",
    "            \"mean_energy\": mean_energy,\n",
    "            \"energy_std\": energy_std,\n",
    "            \"well_mixing\": well_mixing,\n",
    "            \"positive_fraction\": positive_fraction,\n",
    "            \"autocorrelation\": acf,\n",
    "            \"tau\": tau,\n",
    "            \"ess\": ess,\n",
    "            \"time\": elapsed,\n",
    "            \"covariance_condition_number\": np.max(cov_op.eigenvalues[cov_op.eigenvalues > 1e-14])/np.min(cov_op.eigenvalues[cov_op.eigenvalues > 1e-14]) if np.sum(cov_op.eigenvalues > 1e-14) > 0 else np.inf\n",
    "        }\n",
    "        \n",
    "        if save_dir:\n",
    "            np.save(os.path.join(save_dir, \"pcn_fft_samples_allen_cahn.npy\"), samples)\n",
    "            np.save(os.path.join(save_dir, \"pcn_fft_path_integrals.npy\"), path_integrals)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error running FFT pCN: {str(e)}\")\n",
    "        results = {\"error\": str(e)}\n",
    "        elapsed = time.time() - start_time\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with different sizes\n",
    "    print(\"Testing FFT-based pCN for Allen-Cahn SPDE\")\n",
    "    \n",
    "    # Small test\n",
    "    print(\"\\nSmall test (N=32):\")\n",
    "    small_results = benchmark_pcn_allen_cahn_fft(N=32, n_samples=500000, burn_in=50000)\n",
    "    \n",
    "    if \"error\" not in small_results:\n",
    "        print(f\"Acceptance Rate: {small_results['acceptance_rate']:.3f}\")\n",
    "        print(f\"Path Integral Std: {small_results['path_integral_std']:.4f}\")\n",
    "        print(f\"Well Mixing: {small_results['well_mixing']:.3f}\")\n",
    "        print(f\"ESS/sec: {small_results['ess']/small_results['time']:.2f}\" if np.isfinite(small_results['ess']) else \"ESS/sec: NaN\")\n",
    "    \n",
    "    # Medium test  \n",
    "    print(\"\\nMedium test (N=128):\")\n",
    "    medium_results = benchmark_pcn_allen_cahn_fft(N=128, n_samples=1000000, burn_in=100000)\n",
    "    \n",
    "    if \"error\" not in medium_results:\n",
    "        print(f\"Acceptance Rate: {medium_results['acceptance_rate']:.3f}\")\n",
    "        print(f\"Path Integral Std: {medium_results['path_integral_std']:.4f}\")\n",
    "        print(f\"Well Mixing: {medium_results['well_mixing']:.3f}\")\n",
    "        print(f\"ESS/sec: {medium_results['ess']/medium_results['time']:.2f}\" if np.isfinite(medium_results['ess']) else \"ESS/sec: NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba75f3-6f70-4918-8a6a-d0e6f5236465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd258540-67be-41f3-9e50-a90672c082ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MYKERNEL",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
